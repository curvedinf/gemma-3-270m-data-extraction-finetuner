# Copy this file to .env and update the values with your environment-specific secrets.

# Dataset source database (single DuckDB file copied via scp)
# Table `examples` should expose: id, task, prompt_text, response_strong, metadata (JSON), slot_specs (JSON, optional)
DATASET_DB_PATH=data/raw/dataset.duckdb
DATASET_DB_TABLE=examples

# Judge + inference credentials
LITELLM_API_BASE=https://openrouter.ai/api/v1
LITELLM_JUDGE_MODEL=openrouter/qwen/qwen3-coder-30b-a3b-instruct
LITELLM_API_KEY=sk-...

# Model registries and tracking
HUGGINGFACE_TOKEN=hf_...
WANDB_API_KEY=...

# ROCm runtime configuration (adjust per node topology; see AMD's "Running models from Hugging Face" guide)
ROCM_VISIBLE_DEVICES=0
HIP_VISIBLE_DEVICES=0
# Set the correct GFX value for your GPU (e.g., 11.0.0 for MI300, 10.3.0 for MI250)
HSA_OVERRIDE_GFX_VERSION=11.0.0
PYTORCH_HIP_ALLOC_CONF=max_split_size_mb:512
TORCHDYNAMO_DISABLE=1
